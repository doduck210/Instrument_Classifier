{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "instrument_classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOueTNTpU/of8bVdCbvZ6DL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/doduck210/Instrument_Classifier/blob/main/instrument_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiXb970e2Xws",
        "outputId": "095c2f3a-cda6-4fe7-f782-d22ef3e6bded"
      },
      "source": [
        "#for using CoLab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDStGHFt3ISW",
        "outputId": "7e0eb306-860b-4366-fcfd-d65c6099ac4c"
      },
      "source": [
        "#for using PyTorch in CoLab\n",
        "!pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl\n",
        "!pip3 install torchvision"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl is not a supported wheel on this platform.\u001b[0m\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.9.1+cu101)\n",
            "Requirement already satisfied: torch==1.8.1 in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.8.1+cu101)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1->torchvision) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-vIuifIN3TAQ",
        "outputId": "98cc0c6d-860d-4988-d855-9846b3329173"
      },
      "source": [
        "import itertools\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla P100-PCIE-16GB'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLv9B6Ui3szi"
      },
      "source": [
        "20488 number of data     \n",
        "128 (num of instrument) X 50 (notes) X 3 (white noise argumentation) +    \n",
        "46 (num of drum) X 28 (white noise argumentation)   \n",
        "= 20488"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnpEUvga33eE",
        "outputId": "1db9d28e-bcb1-4d69-c8ea-7cd999b4b80f"
      },
      "source": [
        "#데이터 확인\n",
        "npz=np.load('/content/gdrive/My Drive/audio/cqt.npz')\n",
        "x=npz['spec']\n",
        "y=npz['instr']\n",
        "print(\"input shape : \",x.shape) #20488*(168*87)\n",
        "print(\"label shape : \",y.shape) #20488*2"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input shape :  (20488, 168, 87)\n",
            "label shape :  (20488, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpONR1lc5XpR"
      },
      "source": [
        "Building 2 layer CNN Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WwJYwwssuL3"
      },
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "class InstrumentClassifier(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(InstrumentClassifier,self).__init__()\n",
        "    #input : [256, 1, 168, 87]\n",
        "    conv1=nn.Conv2d(1,10,(23,4)) #10@146x84\n",
        "    bn1=nn.BatchNorm2d(10)\n",
        "    #ReLU\n",
        "    pool1=nn.MaxPool2d(2) #10@73x42\n",
        "    conv2=nn.Conv2d(10,3,(6,3)) #3@68x40\n",
        "    bn2=nn.BatchNorm2d(3)\n",
        "    #ReLU\n",
        "    pool2=nn.MaxPool2d(2) #3@34x20\n",
        "\n",
        "    self.conv_module=nn.Sequential(\n",
        "        conv1, bn1,\n",
        "        nn.ReLU(),\n",
        "        pool1, #layer 1\n",
        "        conv2, bn2,\n",
        "        nn.ReLU(),\n",
        "        pool2 #layer 2\n",
        "    )\n",
        "\n",
        "    fc1=nn.Linear(3*34*20,174)\n",
        "    \n",
        "    self.fc_module=nn.Sequential(\n",
        "        fc1\n",
        "    )\n",
        "\n",
        "    if use_cuda:\n",
        "      self.conv_module=self.conv_module.cuda()\n",
        "      self.fc_module=self.fc_module.cuda()\n",
        "    \n",
        "  def forward(self,x):\n",
        "    out=self.conv_module(x)\n",
        "    dim=1\n",
        "    out=out.view(out.size(0),-1)\n",
        "    out=self.fc_module(out)\n",
        "    return F.softmax(out,dim=1)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awqyqqlw0Fbd"
      },
      "source": [
        "cnn=InstrumentClassifier()\n",
        "criterion=torch.nn.CrossEntropyLoss()\n",
        "optimizer=torch.optim.Adam(cnn.parameters(),lr=1e-3)\n",
        "#cnn.load_state_dict(torch.load('/content/gdrive/My Drive/audio/model.pth'))\n",
        "#model.eval()"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHmwpS9L5lFA"
      },
      "source": [
        "Data Split for Dividing Test and Train   \n",
        "and Train for 100 epochs!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Stqw5FcNfOYT",
        "outputId": "fcade5b6-4761-4f2f-d271-46f6ddb6bc83"
      },
      "source": [
        "ridx = list(range(len(x)))\n",
        "random.shuffle(ridx)\n",
        "\n",
        "test_size=len(ridx)//5 # train:test=8:2\n",
        "test_ridx, train_ridx=ridx[:test_size],ridx[test_size:]\n",
        "batch_size = 256\n",
        "\n",
        "trn_acc_list=[]\n",
        "tst_acc_list=[]\n",
        "\n",
        "for e in range(100):\n",
        "  ac=0\n",
        "  for b in range(0,len(train_ridx),batch_size) : \n",
        "    tr=train_ridx[b:b+batch_size]\n",
        "    input=torch.tensor(x[tr])\n",
        "    input=input.unsqueeze(1)\n",
        "    input=input.cuda()\n",
        "    output=torch.tensor(y[tr,0])\n",
        "    output=torch.tensor(output,dtype=torch.long)\n",
        "    output=output.cuda()\n",
        "    #print(\"x : \",input.shape) #torch.Size([256, 1, 168, 87])\n",
        "    #print(\"y : \",output.shape) #torch.Size([256])\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    model_output=cnn(input)\n",
        "    #print(model_output.shape) #torch.Size([256, 174])\n",
        "    loss=criterion(model_output,output)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    for acc in range(0,model_output.shape[0]) : \n",
        "      pre=torch.argmax(model_output[acc])\n",
        "      if pre==output[acc]: ac+=1;\n",
        "    \n",
        "    if (b//batch_size)%10==0 : print('e : ',e,\"loss : \",loss)\n",
        "  print(\"train acc : \",ac/len(train_ridx))\n",
        "\n",
        "  test_ac=0\n",
        "  for b in range(0,len(test_ridx),batch_size) : \n",
        "    tr=test_ridx[b:b+batch_size]\n",
        "    input=torch.tensor(x[tr])\n",
        "    input=input.unsqueeze(1)\n",
        "    input=input.cuda()\n",
        "    output=torch.tensor(y[tr,0])\n",
        "    output=torch.tensor(output,dtype=torch.long)\n",
        "    output=output.cuda()\n",
        "    model_output=cnn(input)\n",
        "    for acc in range(0,model_output.shape[0]):\n",
        "      pre=torch.argmax(model_output[acc])\n",
        "      if pre==output[acc]: test_ac+=1;\n",
        "\n",
        "  print(\"test acc : \",test_ac/len(test_ridx))\n",
        "\n",
        "  trn_acc_list.append(ac/len(train_ridx)*100)\n",
        "  tst_acc_list.append(test_ac/len(test_ridx)*100)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "e :  0 loss :  tensor(5.1588, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  0 loss :  tensor(5.1489, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  0 loss :  tensor(5.1222, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  0 loss :  tensor(5.0949, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  0 loss :  tensor(5.0811, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  0 loss :  tensor(4.9925, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  0 loss :  tensor(5.0240, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.10700994448172778\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test acc :  0.22211374176226506\n",
            "e :  1 loss :  tensor(4.9292, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  1 loss :  tensor(4.9446, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  1 loss :  tensor(4.8701, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  1 loss :  tensor(4.8841, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  1 loss :  tensor(4.8969, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  1 loss :  tensor(4.8408, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  1 loss :  tensor(4.8768, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.33646513330486244\n",
            "test acc :  0.38052233341469366\n",
            "e :  2 loss :  tensor(4.7397, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  2 loss :  tensor(4.7923, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  2 loss :  tensor(4.7192, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  2 loss :  tensor(4.7421, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  2 loss :  tensor(4.7616, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  2 loss :  tensor(4.7692, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  2 loss :  tensor(4.7810, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.45006405954487216\n",
            "test acc :  0.4605809128630705\n",
            "e :  3 loss :  tensor(4.6642, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  3 loss :  tensor(4.7254, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  3 loss :  tensor(4.6467, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  3 loss :  tensor(4.6624, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  3 loss :  tensor(4.7035, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  3 loss :  tensor(4.7124, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  3 loss :  tensor(4.7112, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.5104630589957904\n",
            "test acc :  0.50475958018062\n",
            "e :  4 loss :  tensor(4.5995, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  4 loss :  tensor(4.6727, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  4 loss :  tensor(4.5930, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  4 loss :  tensor(4.6332, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  4 loss :  tensor(4.6519, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  4 loss :  tensor(4.6657, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  4 loss :  tensor(4.6677, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.549569885913001\n",
            "test acc :  0.5291676836709788\n",
            "e :  5 loss :  tensor(4.5788, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  5 loss :  tensor(4.6560, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  5 loss :  tensor(4.5683, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  5 loss :  tensor(4.6076, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  5 loss :  tensor(4.6294, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  5 loss :  tensor(4.6291, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  5 loss :  tensor(4.6206, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.576718931120737\n",
            "test acc :  0.5643153526970954\n",
            "e :  6 loss :  tensor(4.5358, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  6 loss :  tensor(4.6149, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  6 loss :  tensor(4.5583, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  6 loss :  tensor(4.5840, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  6 loss :  tensor(4.6053, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  6 loss :  tensor(4.6123, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  6 loss :  tensor(4.5976, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.6025867854310292\n",
            "test acc :  0.5918965096412009\n",
            "e :  7 loss :  tensor(4.5081, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  7 loss :  tensor(4.5927, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  7 loss :  tensor(4.5408, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  7 loss :  tensor(4.5577, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  7 loss :  tensor(4.5900, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  7 loss :  tensor(4.5838, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  7 loss :  tensor(4.5828, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.6227807943383564\n",
            "test acc :  0.6119111545032951\n",
            "e :  8 loss :  tensor(4.4808, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  8 loss :  tensor(4.5863, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  8 loss :  tensor(4.5238, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  8 loss :  tensor(4.5304, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  8 loss :  tensor(4.5644, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  8 loss :  tensor(4.5670, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  8 loss :  tensor(4.5562, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.6388261851015802\n",
            "test acc :  0.622650720039053\n",
            "e :  9 loss :  tensor(4.4676, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  9 loss :  tensor(4.5757, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  9 loss :  tensor(4.5064, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  9 loss :  tensor(4.5176, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  9 loss :  tensor(4.5202, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  9 loss :  tensor(4.5464, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  9 loss :  tensor(4.5549, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.6542614849612592\n",
            "test acc :  0.6424212838662436\n",
            "e :  10 loss :  tensor(4.4595, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  10 loss :  tensor(4.5608, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  10 loss :  tensor(4.4934, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  10 loss :  tensor(4.5043, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  10 loss :  tensor(4.5196, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  10 loss :  tensor(4.5479, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  10 loss :  tensor(4.5344, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.6650600939539991\n",
            "test acc :  0.6529167683670979\n",
            "e :  11 loss :  tensor(4.4450, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  11 loss :  tensor(4.5437, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  11 loss :  tensor(4.4868, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  11 loss :  tensor(4.5007, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  11 loss :  tensor(4.5067, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  11 loss :  tensor(4.5362, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  11 loss :  tensor(4.5344, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.669391739369166\n",
            "test acc :  0.654625335611423\n",
            "e :  12 loss :  tensor(4.4474, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  12 loss :  tensor(4.5359, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  12 loss :  tensor(4.4838, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  12 loss :  tensor(4.4853, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  12 loss :  tensor(4.4959, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  12 loss :  tensor(4.5236, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  12 loss :  tensor(4.5280, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.6740894393264596\n",
            "test acc :  0.661703685623627\n",
            "e :  13 loss :  tensor(4.4340, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  13 loss :  tensor(4.5341, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  13 loss :  tensor(4.4845, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  13 loss :  tensor(4.4861, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  13 loss :  tensor(4.4941, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  13 loss :  tensor(4.5159, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  13 loss :  tensor(4.5304, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.6773839302056006\n",
            "test acc :  0.6612155235538199\n",
            "e :  14 loss :  tensor(4.4342, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  14 loss :  tensor(4.5273, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  14 loss :  tensor(4.4829, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  14 loss :  tensor(4.4796, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  14 loss :  tensor(4.4964, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  14 loss :  tensor(4.5210, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  14 loss :  tensor(4.5196, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.6801293392715515\n",
            "test acc :  0.6665853063216988\n",
            "e :  15 loss :  tensor(4.4337, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  15 loss :  tensor(4.5252, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  15 loss :  tensor(4.4743, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  15 loss :  tensor(4.4802, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  15 loss :  tensor(4.4892, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  15 loss :  tensor(4.5115, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  15 loss :  tensor(4.5148, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.6818986028918309\n",
            "test acc :  0.6695142787405418\n",
            "e :  16 loss :  tensor(4.4328, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  16 loss :  tensor(4.5196, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  16 loss :  tensor(4.4752, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  16 loss :  tensor(4.4694, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  16 loss :  tensor(4.4854, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  16 loss :  tensor(4.5099, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  16 loss :  tensor(4.5065, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.684155939234946\n",
            "test acc :  0.6702465218452526\n",
            "e :  17 loss :  tensor(4.4306, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  17 loss :  tensor(4.5270, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  17 loss :  tensor(4.4762, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  17 loss :  tensor(4.4633, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  17 loss :  tensor(4.4803, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  17 loss :  tensor(4.5106, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  17 loss :  tensor(4.5119, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.6865352937587701\n",
            "test acc :  0.6721991701244814\n",
            "e :  18 loss :  tensor(4.4302, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  18 loss :  tensor(4.5251, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  18 loss :  tensor(4.4637, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  18 loss :  tensor(4.4619, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  18 loss :  tensor(4.4784, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  18 loss :  tensor(4.5165, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  18 loss :  tensor(4.5048, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.6894637300957843\n",
            "test acc :  0.6770807908225531\n",
            "e :  19 loss :  tensor(4.4248, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  19 loss :  tensor(4.5179, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  19 loss :  tensor(4.4622, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  19 loss :  tensor(4.4631, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  19 loss :  tensor(4.4803, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  19 loss :  tensor(4.5036, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  19 loss :  tensor(4.5020, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.6911109755353547\n",
            "test acc :  0.6780571149621675\n",
            "e :  20 loss :  tensor(4.4281, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  20 loss :  tensor(4.5246, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  20 loss :  tensor(4.4673, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  20 loss :  tensor(4.4620, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  20 loss :  tensor(4.4851, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  20 loss :  tensor(4.5025, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  20 loss :  tensor(4.5082, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.6901958391800378\n",
            "test acc :  0.6792775201366854\n",
            "e :  21 loss :  tensor(4.4266, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  21 loss :  tensor(4.5135, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  21 loss :  tensor(4.4615, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  21 loss :  tensor(4.4564, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  21 loss :  tensor(4.4764, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  21 loss :  tensor(4.5063, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  21 loss :  tensor(4.5004, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.6934903300591788\n",
            "test acc :  0.6819624115206249\n",
            "e :  22 loss :  tensor(4.4265, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  22 loss :  tensor(4.5132, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  22 loss :  tensor(4.4590, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  22 loss :  tensor(4.4543, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  22 loss :  tensor(4.4723, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  22 loss :  tensor(4.5019, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  22 loss :  tensor(4.4987, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.6966628027576108\n",
            "test acc :  0.6846473029045643\n",
            "e :  23 loss :  tensor(4.4233, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  23 loss :  tensor(4.5089, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  23 loss :  tensor(4.4563, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  23 loss :  tensor(4.4560, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  23 loss :  tensor(4.4707, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  23 loss :  tensor(4.5078, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  23 loss :  tensor(4.4990, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.6984930754682448\n",
            "test acc :  0.6851354649743715\n",
            "e :  24 loss :  tensor(4.4232, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  24 loss :  tensor(4.5073, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  24 loss :  tensor(4.4464, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  24 loss :  tensor(4.4504, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  24 loss :  tensor(4.4719, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  24 loss :  tensor(4.5011, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  24 loss :  tensor(4.4973, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.6987371118296626\n",
            "test acc :  0.6853795460092751\n",
            "e :  25 loss :  tensor(4.4257, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  25 loss :  tensor(4.5095, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  25 loss :  tensor(4.4481, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  25 loss :  tensor(4.4502, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  25 loss :  tensor(4.4708, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  25 loss :  tensor(4.5011, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  25 loss :  tensor(4.4938, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.700628393630651\n",
            "test acc :  0.6887966804979253\n",
            "e :  26 loss :  tensor(4.4233, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  26 loss :  tensor(4.5061, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  26 loss :  tensor(4.4470, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  26 loss :  tensor(4.4442, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  26 loss :  tensor(4.4700, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  26 loss :  tensor(4.5011, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  26 loss :  tensor(4.4931, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.7017875663473857\n",
            "test acc :  0.6895289236026361\n",
            "e :  27 loss :  tensor(4.4206, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  27 loss :  tensor(4.5063, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  27 loss :  tensor(4.4422, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  27 loss :  tensor(4.4455, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  27 loss :  tensor(4.4708, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  27 loss :  tensor(4.4986, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  27 loss :  tensor(4.4929, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.7015435299859679\n",
            "test acc :  0.6783011959970711\n",
            "e :  28 loss :  tensor(4.4364, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  28 loss :  tensor(4.5103, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  28 loss :  tensor(4.4529, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  28 loss :  tensor(4.4470, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  28 loss :  tensor(4.4707, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  28 loss :  tensor(4.4988, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  28 loss :  tensor(4.4914, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.6988591300103716\n",
            "test acc :  0.6873321942885038\n",
            "e :  29 loss :  tensor(4.4209, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  29 loss :  tensor(4.5055, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  29 loss :  tensor(4.4429, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  29 loss :  tensor(4.4455, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  29 loss :  tensor(4.4671, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  29 loss :  tensor(4.5095, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  29 loss :  tensor(4.4943, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.7025806845219937\n",
            "test acc :  0.6892848425677325\n",
            "e :  30 loss :  tensor(4.4207, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  30 loss :  tensor(4.5057, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  30 loss :  tensor(4.4478, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  30 loss :  tensor(4.4626, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  30 loss :  tensor(4.4705, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  30 loss :  tensor(4.4972, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  30 loss :  tensor(4.5015, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.6981880300164724\n",
            "test acc :  0.6861117891139858\n",
            "e :  31 loss :  tensor(4.4328, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  31 loss :  tensor(4.5091, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  31 loss :  tensor(4.4442, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  31 loss :  tensor(4.4624, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  31 loss :  tensor(4.4702, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  31 loss :  tensor(4.4933, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  31 loss :  tensor(4.4914, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.6972118845708011\n",
            "test acc :  0.6870881132536002\n",
            "e :  32 loss :  tensor(4.4305, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  32 loss :  tensor(4.5113, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  32 loss :  tensor(4.4425, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  32 loss :  tensor(4.4630, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  32 loss :  tensor(4.4700, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  32 loss :  tensor(4.4936, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  32 loss :  tensor(4.4936, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.6977609663839912\n",
            "test acc :  0.6870881132536002\n",
            "e :  33 loss :  tensor(4.4290, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  33 loss :  tensor(4.5088, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  33 loss :  tensor(4.4422, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  33 loss :  tensor(4.4622, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  33 loss :  tensor(4.4727, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  33 loss :  tensor(4.4930, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  33 loss :  tensor(4.4893, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.6976389482032823\n",
            "test acc :  0.6868440322186966\n",
            "e :  34 loss :  tensor(4.4278, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  34 loss :  tensor(4.5085, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  34 loss :  tensor(4.4421, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  34 loss :  tensor(4.4621, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  34 loss :  tensor(4.4699, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  34 loss :  tensor(4.4930, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  34 loss :  tensor(4.4896, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.6979439936550546\n",
            "test acc :  0.687820356358311\n",
            "e :  35 loss :  tensor(4.4302, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  35 loss :  tensor(4.5087, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  35 loss :  tensor(4.4421, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  35 loss :  tensor(4.4621, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  35 loss :  tensor(4.4697, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  35 loss :  tensor(4.4929, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  35 loss :  tensor(4.4892, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.6979439936550546\n",
            "test acc :  0.6885525994630217\n",
            "e :  36 loss :  tensor(4.4292, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  36 loss :  tensor(4.5087, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  36 loss :  tensor(4.4421, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  36 loss :  tensor(4.4616, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  36 loss :  tensor(4.4733, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  36 loss :  tensor(4.4929, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  36 loss :  tensor(4.4914, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.6977609663839912\n",
            "test acc :  0.6880644373932145\n",
            "e :  37 loss :  tensor(4.4275, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  37 loss :  tensor(4.5087, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  37 loss :  tensor(4.4421, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  37 loss :  tensor(4.4655, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  37 loss :  tensor(4.4698, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  37 loss :  tensor(4.4928, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  37 loss :  tensor(4.4895, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.6976999572936368\n",
            "test acc :  0.6883085184281181\n",
            "e :  38 loss :  tensor(4.4280, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  38 loss :  tensor(4.5113, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  38 loss :  tensor(4.4447, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  38 loss :  tensor(4.4627, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  38 loss :  tensor(4.4712, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  38 loss :  tensor(4.4929, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  38 loss :  tensor(4.4890, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.6978219754743457\n",
            "test acc :  0.6885525994630217\n",
            "e :  39 loss :  tensor(4.4278, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  39 loss :  tensor(4.5085, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  39 loss :  tensor(4.4420, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  39 loss :  tensor(4.4645, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  39 loss :  tensor(4.4695, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  39 loss :  tensor(4.4928, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  39 loss :  tensor(4.4890, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.6979439936550546\n",
            "test acc :  0.6890407615328289\n",
            "e :  40 loss :  tensor(4.4268, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  40 loss :  tensor(4.5086, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  40 loss :  tensor(4.4420, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  40 loss :  tensor(4.4616, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  40 loss :  tensor(4.4698, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  40 loss :  tensor(4.4929, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  40 loss :  tensor(4.4935, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.6978219754743457\n",
            "test acc :  0.6883085184281181\n",
            "e :  41 loss :  tensor(4.4239, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  41 loss :  tensor(4.5076, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  41 loss :  tensor(4.4419, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  41 loss :  tensor(4.4621, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  41 loss :  tensor(4.4708, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  41 loss :  tensor(4.4929, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  41 loss :  tensor(4.4926, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.6984320663778903\n",
            "test acc :  0.6875762753234074\n",
            "e :  42 loss :  tensor(4.4264, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  42 loss :  tensor(4.5041, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  42 loss :  tensor(4.4420, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  42 loss :  tensor(4.4617, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  42 loss :  tensor(4.4701, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  42 loss :  tensor(4.4928, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  42 loss :  tensor(4.4890, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.6984320663778903\n",
            "test acc :  0.6883085184281181\n",
            "e :  43 loss :  tensor(4.4261, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  43 loss :  tensor(4.5026, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  43 loss :  tensor(4.4419, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  43 loss :  tensor(4.4618, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  43 loss :  tensor(4.4696, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  43 loss :  tensor(4.4928, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  43 loss :  tensor(4.4917, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.6986761027393081\n",
            "test acc :  0.6885525994630217\n",
            "e :  44 loss :  tensor(4.4242, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  44 loss :  tensor(4.5013, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  44 loss :  tensor(4.4419, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  44 loss :  tensor(4.4652, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  44 loss :  tensor(4.4695, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  44 loss :  tensor(4.4928, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  44 loss :  tensor(4.4917, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.6986761027393081\n",
            "test acc :  0.6880644373932145\n",
            "e :  45 loss :  tensor(4.4266, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  45 loss :  tensor(4.5007, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  45 loss :  tensor(4.4419, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  45 loss :  tensor(4.4644, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  45 loss :  tensor(4.4694, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  45 loss :  tensor(4.4928, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  45 loss :  tensor(4.4900, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.6986150936489537\n",
            "test acc :  0.6885525994630217\n",
            "e :  46 loss :  tensor(4.4266, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  46 loss :  tensor(4.5007, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  46 loss :  tensor(4.4419, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  46 loss :  tensor(4.4630, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  46 loss :  tensor(4.4694, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  46 loss :  tensor(4.4932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  46 loss :  tensor(4.4925, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.6987371118296626\n",
            "test acc :  0.6880644373932145\n",
            "e :  47 loss :  tensor(4.4266, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  47 loss :  tensor(4.5005, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  47 loss :  tensor(4.4422, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  47 loss :  tensor(4.4639, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  47 loss :  tensor(4.4694, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  47 loss :  tensor(4.4928, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  47 loss :  tensor(4.4921, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.6983100481971813\n",
            "test acc :  0.6895289236026361\n",
            "e :  48 loss :  tensor(4.4266, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  48 loss :  tensor(4.5005, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  48 loss :  tensor(4.4419, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  48 loss :  tensor(4.4654, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  48 loss :  tensor(4.4735, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  48 loss :  tensor(4.4946, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  48 loss :  tensor(4.4901, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.6984320663778903\n",
            "test acc :  0.6868440322186966\n",
            "e :  49 loss :  tensor(4.4271, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  49 loss :  tensor(4.5027, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  49 loss :  tensor(4.4484, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  49 loss :  tensor(4.4672, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  49 loss :  tensor(4.4779, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  49 loss :  tensor(4.5015, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  49 loss :  tensor(4.4960, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.6951375754987493\n",
            "test acc :  0.6809860873810105\n",
            "e :  50 loss :  tensor(4.4344, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  50 loss :  tensor(4.5137, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  50 loss :  tensor(4.4554, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  50 loss :  tensor(4.4758, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  50 loss :  tensor(4.4762, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  50 loss :  tensor(4.5080, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  50 loss :  tensor(4.4990, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.690744920993228\n",
            "test acc :  0.672443251159385\n",
            "e :  51 loss :  tensor(4.4487, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  51 loss :  tensor(4.5021, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  51 loss :  tensor(4.4455, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  51 loss :  tensor(4.4787, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  51 loss :  tensor(4.4822, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  51 loss :  tensor(4.4963, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  51 loss :  tensor(4.4992, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.690622902812519\n",
            "test acc :  0.6726873321942886\n",
            "e :  52 loss :  tensor(4.4477, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  52 loss :  tensor(4.5076, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  52 loss :  tensor(4.4427, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  52 loss :  tensor(4.4573, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  52 loss :  tensor(4.4738, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  52 loss :  tensor(4.4940, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  52 loss :  tensor(4.4895, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.6962357391251296\n",
            "test acc :  0.6946546253356114\n",
            "e :  53 loss :  tensor(4.4177, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  53 loss :  tensor(4.4994, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  53 loss :  tensor(4.4396, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  53 loss :  tensor(4.4421, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  53 loss :  tensor(4.4662, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  53 loss :  tensor(4.4935, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  53 loss :  tensor(4.4857, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.7042279299615642\n",
            "test acc :  0.6914815718818648\n",
            "e :  54 loss :  tensor(4.4145, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  54 loss :  tensor(4.4937, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  54 loss :  tensor(4.4383, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  54 loss :  tensor(4.4416, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  54 loss :  tensor(4.4674, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  54 loss :  tensor(4.4947, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  54 loss :  tensor(4.4942, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.7050210481361723\n",
            "test acc :  0.6944105443007078\n",
            "e :  55 loss :  tensor(4.4135, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  55 loss :  tensor(4.4929, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  55 loss :  tensor(4.4382, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  55 loss :  tensor(4.4383, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  55 loss :  tensor(4.4658, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  55 loss :  tensor(4.4954, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  55 loss :  tensor(4.4854, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.7055701299493624\n",
            "test acc :  0.6941664632658042\n",
            "e :  56 loss :  tensor(4.4134, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  56 loss :  tensor(4.4929, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  56 loss :  tensor(4.4382, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  56 loss :  tensor(4.4345, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  56 loss :  tensor(4.4694, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  56 loss :  tensor(4.4929, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  56 loss :  tensor(4.4887, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.7060582026721982\n",
            "test acc :  0.6946546253356114\n",
            "e :  57 loss :  tensor(4.4148, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  57 loss :  tensor(4.4928, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  57 loss :  tensor(4.4381, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  57 loss :  tensor(4.4373, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  57 loss :  tensor(4.4656, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  57 loss :  tensor(4.4929, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  57 loss :  tensor(4.4880, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.7057531572204259\n",
            "test acc :  0.6961191115450329\n",
            "e :  58 loss :  tensor(4.4121, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  58 loss :  tensor(4.4928, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  58 loss :  tensor(4.4382, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  58 loss :  tensor(4.4368, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  58 loss :  tensor(4.4623, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  58 loss :  tensor(4.4936, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  58 loss :  tensor(4.4860, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.7064242572143249\n",
            "test acc :  0.6956309494752257\n",
            "e :  59 loss :  tensor(4.4151, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  59 loss :  tensor(4.4973, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  59 loss :  tensor(4.4382, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  59 loss :  tensor(4.4342, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  59 loss :  tensor(4.4618, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  59 loss :  tensor(4.4930, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  59 loss :  tensor(4.4894, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.7066682935757428\n",
            "test acc :  0.6961191115450329\n",
            "e :  60 loss :  tensor(4.4150, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  60 loss :  tensor(4.4889, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  60 loss :  tensor(4.4382, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  60 loss :  tensor(4.4350, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  60 loss :  tensor(4.4618, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  60 loss :  tensor(4.4933, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  60 loss :  tensor(4.4855, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.7068513208468061\n",
            "test acc :  0.6953868684403222\n",
            "e :  61 loss :  tensor(4.4147, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  61 loss :  tensor(4.4944, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  61 loss :  tensor(4.4486, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  61 loss :  tensor(4.4352, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  61 loss :  tensor(4.4624, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  61 loss :  tensor(4.4931, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  61 loss :  tensor(4.4859, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.7036178390580197\n",
            "test acc :  0.6944105443007078\n",
            "e :  62 loss :  tensor(4.4165, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  62 loss :  tensor(4.4908, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  62 loss :  tensor(4.4408, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  62 loss :  tensor(4.4359, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  62 loss :  tensor(4.4694, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  62 loss :  tensor(4.4932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  62 loss :  tensor(4.4858, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.7052650844975902\n",
            "test acc :  0.6929460580912863\n",
            "e :  63 loss :  tensor(4.4196, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  63 loss :  tensor(4.4893, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  63 loss :  tensor(4.4422, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  63 loss :  tensor(4.4337, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  63 loss :  tensor(4.4628, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  63 loss :  tensor(4.4931, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  63 loss :  tensor(4.4859, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.7053871026782991\n",
            "test acc :  0.6956309494752257\n",
            "e :  64 loss :  tensor(4.4127, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  64 loss :  tensor(4.4890, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  64 loss :  tensor(4.4383, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  64 loss :  tensor(4.4301, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  64 loss :  tensor(4.4617, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  64 loss :  tensor(4.4930, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  64 loss :  tensor(4.4897, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.7067903117564517\n",
            "test acc :  0.6961191115450329\n",
            "e :  65 loss :  tensor(4.4137, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  65 loss :  tensor(4.4891, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  65 loss :  tensor(4.4382, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  65 loss :  tensor(4.4317, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  65 loss :  tensor(4.4628, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  65 loss :  tensor(4.4928, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  65 loss :  tensor(4.4853, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.7072783844792874\n",
            "test acc :  0.6958750305101293\n",
            "e :  66 loss :  tensor(4.4149, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  66 loss :  tensor(4.4889, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  66 loss :  tensor(4.4381, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  66 loss :  tensor(4.4304, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  66 loss :  tensor(4.4617, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  66 loss :  tensor(4.4928, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  66 loss :  tensor(4.4850, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.7074004026599964\n",
            "test acc :  0.6968513546497437\n",
            "e :  67 loss :  tensor(4.4149, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  67 loss :  tensor(4.4888, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  67 loss :  tensor(4.4381, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  67 loss :  tensor(4.4301, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  67 loss :  tensor(4.4619, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  67 loss :  tensor(4.4932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  67 loss :  tensor(4.4857, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.7076444390214142\n",
            "test acc :  0.697827678789358\n",
            "e :  68 loss :  tensor(4.4144, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  68 loss :  tensor(4.4889, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  68 loss :  tensor(4.4381, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  68 loss :  tensor(4.4309, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  68 loss :  tensor(4.4617, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  68 loss :  tensor(4.4929, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  68 loss :  tensor(4.4896, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.7074614117503508\n",
            "test acc :  0.6975835977544544\n",
            "e :  69 loss :  tensor(4.4149, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  69 loss :  tensor(4.4889, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  69 loss :  tensor(4.4344, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  69 loss :  tensor(4.4304, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  69 loss :  tensor(4.4620, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  69 loss :  tensor(4.4956, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  69 loss :  tensor(4.4851, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.7077664572021232\n",
            "test acc :  0.6946546253356114\n",
            "e :  70 loss :  tensor(4.4165, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  70 loss :  tensor(4.4894, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  70 loss :  tensor(4.4344, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  70 loss :  tensor(4.4305, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  70 loss :  tensor(4.4617, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  70 loss :  tensor(4.4932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  70 loss :  tensor(4.4867, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.7069123299371607\n",
            "test acc :  0.6919697339516719\n",
            "e :  71 loss :  tensor(4.4202, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  71 loss :  tensor(4.5002, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  71 loss :  tensor(4.4400, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  71 loss :  tensor(4.4307, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  71 loss :  tensor(4.4641, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  71 loss :  tensor(4.4936, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  71 loss :  tensor(4.4929, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.7054481117686535\n",
            "test acc :  0.6929460580912863\n",
            "e :  72 loss :  tensor(4.4215, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  72 loss :  tensor(4.4909, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  72 loss :  tensor(4.4418, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  72 loss :  tensor(4.4347, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  72 loss :  tensor(4.4626, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  72 loss :  tensor(4.4938, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  72 loss :  tensor(4.4877, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.7066682935757428\n",
            "test acc :  0.6941664632658042\n",
            "e :  73 loss :  tensor(4.4184, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  73 loss :  tensor(4.4892, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  73 loss :  tensor(4.4378, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  73 loss :  tensor(4.4271, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  73 loss :  tensor(4.4636, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  73 loss :  tensor(4.4930, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  73 loss :  tensor(4.4850, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.7076444390214142\n",
            "test acc :  0.6980717598242616\n",
            "e :  74 loss :  tensor(4.4137, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  74 loss :  tensor(4.4890, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  74 loss :  tensor(4.4424, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  74 loss :  tensor(4.4279, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  74 loss :  tensor(4.4640, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  74 loss :  tensor(4.4932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  74 loss :  tensor(4.4859, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.7081325117442498\n",
            "test acc :  0.6973395167195509\n",
            "e :  75 loss :  tensor(4.4164, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  75 loss :  tensor(4.4893, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  75 loss :  tensor(4.4391, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  75 loss :  tensor(4.4266, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  75 loss :  tensor(4.4621, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  75 loss :  tensor(4.4929, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  75 loss :  tensor(4.4838, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.7080715026538954\n",
            "test acc :  0.6834268977300464\n",
            "e :  76 loss :  tensor(4.4193, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  76 loss :  tensor(4.5808, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  76 loss :  tensor(4.5158, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  76 loss :  tensor(4.4985, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  76 loss :  tensor(4.4914, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  76 loss :  tensor(4.5306, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  76 loss :  tensor(4.5092, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.6677444939295956\n",
            "test acc :  0.6773248718574567\n",
            "e :  77 loss :  tensor(4.4394, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  77 loss :  tensor(4.5043, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  77 loss :  tensor(4.4566, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  77 loss :  tensor(4.4481, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  77 loss :  tensor(4.4664, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  77 loss :  tensor(4.5072, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  77 loss :  tensor(4.4972, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.6956866573119395\n",
            "test acc :  0.6890407615328289\n",
            "e :  78 loss :  tensor(4.4268, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  78 loss :  tensor(4.4979, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  78 loss :  tensor(4.4536, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  78 loss :  tensor(4.4455, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  78 loss :  tensor(4.4698, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  78 loss :  tensor(4.5009, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  78 loss :  tensor(4.4945, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.7019705936184492\n",
            "test acc :  0.6914815718818648\n",
            "e :  79 loss :  tensor(4.4268, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  79 loss :  tensor(4.4916, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  79 loss :  tensor(4.4504, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  79 loss :  tensor(4.4422, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  79 loss :  tensor(4.4663, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  79 loss :  tensor(4.5007, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  79 loss :  tensor(4.4938, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.7017875663473857\n",
            "test acc :  0.6931901391261899\n",
            "e :  80 loss :  tensor(4.4241, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  80 loss :  tensor(4.4964, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  80 loss :  tensor(4.4499, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  80 loss :  tensor(4.4432, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  80 loss :  tensor(4.4630, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  80 loss :  tensor(4.4971, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  80 loss :  tensor(4.4951, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.7028247208834116\n",
            "test acc :  0.6917256529167684\n",
            "e :  81 loss :  tensor(4.4242, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  81 loss :  tensor(4.4930, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  81 loss :  tensor(4.4499, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  81 loss :  tensor(4.4435, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  81 loss :  tensor(4.4624, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  81 loss :  tensor(4.4968, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  81 loss :  tensor(4.4930, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.7030687572448295\n",
            "test acc :  0.6905052477422504\n",
            "e :  82 loss :  tensor(4.4236, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  82 loss :  tensor(4.4938, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  82 loss :  tensor(4.4500, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  82 loss :  tensor(4.4440, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  82 loss :  tensor(4.4656, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  82 loss :  tensor(4.5001, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  82 loss :  tensor(4.4904, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.703129766335184\n",
            "test acc :  0.693678301195997\n",
            "e :  83 loss :  tensor(4.4216, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  83 loss :  tensor(4.4928, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  83 loss :  tensor(4.4499, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  83 loss :  tensor(4.4442, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  83 loss :  tensor(4.4623, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  83 loss :  tensor(4.4971, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  83 loss :  tensor(4.4955, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.7029467390641205\n",
            "test acc :  0.6924578960214791\n",
            "e :  84 loss :  tensor(4.4186, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  84 loss :  tensor(4.4928, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  84 loss :  tensor(4.4491, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  84 loss :  tensor(4.4422, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  84 loss :  tensor(4.4627, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  84 loss :  tensor(4.4969, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  84 loss :  tensor(4.4892, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.7041059117808554\n",
            "test acc :  0.6961191115450329\n",
            "e :  85 loss :  tensor(4.4230, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  85 loss :  tensor(4.4906, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  85 loss :  tensor(4.4345, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  85 loss :  tensor(4.4272, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  85 loss :  tensor(4.4580, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  85 loss :  tensor(4.4932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  85 loss :  tensor(4.4854, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.7094747117320481\n",
            "test acc :  0.7007566512082011\n",
            "e :  86 loss :  tensor(4.4124, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  86 loss :  tensor(4.4890, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  86 loss :  tensor(4.4344, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  86 loss :  tensor(4.4276, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  86 loss :  tensor(4.4578, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  86 loss :  tensor(4.4929, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  86 loss :  tensor(4.4882, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.7102068208163016\n",
            "test acc :  0.7000244081034903\n",
            "e :  87 loss :  tensor(4.4150, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  87 loss :  tensor(4.4891, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  87 loss :  tensor(4.4343, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  87 loss :  tensor(4.4287, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  87 loss :  tensor(4.4580, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  87 loss :  tensor(4.4929, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  87 loss :  tensor(4.4846, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.7099627844548838\n",
            "test acc :  0.7010007322431047\n",
            "e :  88 loss :  tensor(4.4071, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  88 loss :  tensor(4.4890, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  88 loss :  tensor(4.4343, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  88 loss :  tensor(4.4267, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  88 loss :  tensor(4.4577, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  88 loss :  tensor(4.4991, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  88 loss :  tensor(4.4824, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.7103288389970106\n",
            "test acc :  0.6997803270685867\n",
            "e :  89 loss :  tensor(4.4084, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  89 loss :  tensor(4.4890, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  89 loss :  tensor(4.4343, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  89 loss :  tensor(4.4304, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  89 loss :  tensor(4.4580, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  89 loss :  tensor(4.4929, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  89 loss :  tensor(4.4811, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.7106338844487828\n",
            "test acc :  0.7012448132780082\n",
            "e :  90 loss :  tensor(4.4039, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  90 loss :  tensor(4.4889, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  90 loss :  tensor(4.4346, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  90 loss :  tensor(4.4307, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  90 loss :  tensor(4.4578, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  90 loss :  tensor(4.4932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  90 loss :  tensor(4.4824, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.7109389299005552\n",
            "test acc :  0.7005125701732975\n",
            "e :  91 loss :  tensor(4.4065, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  91 loss :  tensor(4.4907, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  91 loss :  tensor(4.4343, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  91 loss :  tensor(4.4304, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  91 loss :  tensor(4.4698, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  91 loss :  tensor(4.4930, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  91 loss :  tensor(4.4824, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.7101458117259472\n",
            "test acc :  0.701977056382719\n",
            "e :  92 loss :  tensor(4.4083, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  92 loss :  tensor(4.4960, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  92 loss :  tensor(4.4343, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  92 loss :  tensor(4.4305, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  92 loss :  tensor(4.4579, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  92 loss :  tensor(4.4929, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  92 loss :  tensor(4.4773, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.711304984442682\n",
            "test acc :  0.701977056382719\n",
            "e :  93 loss :  tensor(4.4066, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  93 loss :  tensor(4.4890, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  93 loss :  tensor(4.4345, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  93 loss :  tensor(4.4293, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  93 loss :  tensor(4.4577, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  93 loss :  tensor(4.4929, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  93 loss :  tensor(4.4777, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.711976084436581\n",
            "test acc :  0.701977056382719\n",
            "e :  94 loss :  tensor(4.4068, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  94 loss :  tensor(4.4889, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  94 loss :  tensor(4.4343, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  94 loss :  tensor(4.4304, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  94 loss :  tensor(4.4580, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  94 loss :  tensor(4.4928, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  94 loss :  tensor(4.4772, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.7120370935269356\n",
            "test acc :  0.7029533805223334\n",
            "e :  95 loss :  tensor(4.4040, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  95 loss :  tensor(4.4889, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  95 loss :  tensor(4.4342, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  95 loss :  tensor(4.4291, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  95 loss :  tensor(4.4577, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  95 loss :  tensor(4.4929, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  95 loss :  tensor(4.4800, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.7119150753462266\n",
            "test acc :  0.7022211374176226\n",
            "e :  96 loss :  tensor(4.4070, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  96 loss :  tensor(4.4889, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  96 loss :  tensor(4.4342, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  96 loss :  tensor(4.4304, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  96 loss :  tensor(4.4592, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  96 loss :  tensor(4.4928, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  96 loss :  tensor(4.4773, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.7116710389848088\n",
            "test acc :  0.701977056382719\n",
            "e :  97 loss :  tensor(4.4071, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  97 loss :  tensor(4.4890, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  97 loss :  tensor(4.4342, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  97 loss :  tensor(4.4302, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  97 loss :  tensor(4.4577, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  97 loss :  tensor(4.4928, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  97 loss :  tensor(4.4772, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.71209810261729\n",
            "test acc :  0.7039297046619478\n",
            "e :  98 loss :  tensor(4.4070, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  98 loss :  tensor(4.4889, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  98 loss :  tensor(4.4342, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  98 loss :  tensor(4.4299, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  98 loss :  tensor(4.4579, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  98 loss :  tensor(4.4963, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  98 loss :  tensor(4.4775, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.7116100298944543\n",
            "test acc :  0.7012448132780082\n",
            "e :  99 loss :  tensor(4.4043, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  99 loss :  tensor(4.4890, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  99 loss :  tensor(4.4357, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  99 loss :  tensor(4.4267, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  99 loss :  tensor(4.4598, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  99 loss :  tensor(4.4929, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  99 loss :  tensor(4.4774, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.7122201207979989\n",
            "test acc :  0.704417866731755\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYJOEOcxzHnB"
      },
      "source": [
        "torch.save(cnn.state_dict(),'/content/gdrive/My Drive/audio/model.pth')"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cb1vYibLuUOO"
      },
      "source": [
        "Code to trace accuracy changing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "aMHBheBKuTAI",
        "outputId": "330a91ca-e8bb-472c-9c76-006ea9958c8b"
      },
      "source": [
        "plt.figure(figsize=(16,9))\n",
        "x_range=range(len(trn_acc_list))\n",
        "plt.plot(x_range,trn_acc_list,label=\"train\")\n",
        "plt.plot(x_range,tst_acc_list,label=\"test\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"acc\")"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'acc')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}