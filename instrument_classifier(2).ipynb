{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "instrument_classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNZFo/raXat7s+i0u7yOJRS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/doduck210/Instrument_Classifier/blob/main/instrument_classifier(2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiXb970e2Xws",
        "outputId": "8cb8d176-603e-4f84-8638-406a0a934708"
      },
      "source": [
        "#for using CoLab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDStGHFt3ISW",
        "outputId": "25f938c7-4a6a-4b7c-f9ef-c64216d460a1"
      },
      "source": [
        "#for using CoLab\n",
        "!pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl\n",
        "!pip3 install torchvision"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl is not a supported wheel on this platform.\u001b[0m\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.9.1+cu101)\n",
            "Requirement already satisfied: torch==1.8.1 in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.8.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1->torchvision) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-vIuifIN3TAQ",
        "outputId": "5371693c-97e0-4d74-a327-f740ee539a2c"
      },
      "source": [
        "import itertools\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla K80'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnpEUvga33eE",
        "outputId": "24f0f0a8-0f30-401c-ecce-2217ce550370"
      },
      "source": [
        "#데이터 확인\n",
        "npz=np.load('/content/gdrive/My Drive/audio/cqt.npz')\n",
        "x=npz['spec']\n",
        "y=npz['instr']\n",
        "print(\"input shape : \",x.shape) \n",
        "print(\"label shape : \",y.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input shape :  (20488, 168, 87)\n",
            "label shape :  (20488, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WwJYwwssuL3"
      },
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "class InstrumentClassifier(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(InstrumentClassifier,self).__init__()\n",
        "    #input : [256, 1, 168, 87]\n",
        "    conv1=nn.Conv2d(1,6,(23,4)) #6@146x84\n",
        "    bn1=nn.BatchNorm2d(6)\n",
        "    #ReLU\n",
        "    pool1=nn.MaxPool2d(2) #6@73x42\n",
        "    conv2=nn.Conv2d(6,3,(6,3)) #10@68x40\n",
        "    bn2=nn.BatchNorm2d(3)\n",
        "    #ReLU\n",
        "    pool2=nn.MaxPool2d(2) #10@34x20\n",
        "    conv3=nn.Conv2d(16,32,(5,5)) #28@30x16\n",
        "    bn3=nn.BatchNorm2d(32)\n",
        "    #ReLU\n",
        "    pool3=nn.MaxPool2d(2) #28@15x8\n",
        "    \n",
        "    dropout= nn.Dropout()\n",
        "    #nn.init.xavier_uniform_(conv1.weight)\n",
        "    #nn.init.xavier_uniform_(conv2.weight)\n",
        "    #nn.init.xavier_uniform_(conv3.weight)\n",
        "\n",
        "    self.conv_module=nn.Sequential(\n",
        "        conv1, bn1,\n",
        "        nn.ReLU(),\n",
        "        pool1,\n",
        "        conv2, bn2,\n",
        "        nn.ReLU(),\n",
        "        pool2#,\n",
        "        #conv3,\n",
        "        #nn.ReLU(),# dropout,\n",
        "        #pool3\n",
        "    )\n",
        "\n",
        "    fc1=nn.Linear(3*34*20,174)\n",
        "    #ReLU\n",
        "    #fc2=nn.Linear(500,174)\n",
        "    \n",
        "    self.fc_module=nn.Sequential(\n",
        "        fc1\n",
        "        #nn.ReLU(),\n",
        "        #fc2\n",
        "    )\n",
        "    if use_cuda:\n",
        "      self.conv_module=self.conv_module.cuda()\n",
        "      self.fc_module=self.fc_module.cuda()\n",
        "    \n",
        "  def forward(self,x):\n",
        "    out=self.conv_module(x)\n",
        "    dim=1\n",
        "    out=out.view(out.size(0),-1)\n",
        "    out=self.fc_module(out)\n",
        "    return F.softmax(out,dim=1)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awqyqqlw0Fbd"
      },
      "source": [
        "cnn=InstrumentClassifier()\n",
        "criterion=torch.nn.CrossEntropyLoss()\n",
        "optimizer=torch.optim.Adam(cnn.parameters(),lr=1e-3)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Stqw5FcNfOYT",
        "outputId": "3686af4e-1bb7-4989-d5d1-3ea67be48e3f"
      },
      "source": [
        "ridx = list(range(len(x)))\n",
        "random.shuffle(ridx)\n",
        "\n",
        "test_size=len(ridx)//5 # train:test=8:2\n",
        "test_ridx, train_ridx=ridx[:test_size],ridx[test_size:]\n",
        "batch_size = 256\n",
        "\n",
        "for e in range(100):\n",
        "  ac=0\n",
        "  for b in range(0,len(train_ridx),batch_size) : \n",
        "    tr=train_ridx[b:b+batch_size]\n",
        "    input=torch.tensor(x[tr])\n",
        "    input=input.unsqueeze(1)\n",
        "    input=input.cuda()\n",
        "    output=torch.tensor(y[tr,0])\n",
        "    output=torch.tensor(output,dtype=torch.long)\n",
        "    output=output.cuda()\n",
        "    #print(\"x : \",input.shape) #torch.Size([256, 1, 168, 87])\n",
        "    #print(\"y : \",output.shape) #torch.Size([256])\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    model_output=cnn(input) #torch.Size([256, 174])\n",
        "    #print(model_output.shape)\n",
        "    loss=criterion(model_output,output)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    for acc in range(0,model_output.shape[0]) : \n",
        "      pre=torch.argmax(model_output[acc])\n",
        "      if pre==output[acc]: ac+=1;\n",
        "    \n",
        "    if (b//batch_size)%10==0 : print('e : ',e,\"loss : \",loss)\n",
        "  print(\"train acc : \",ac/len(train_ridx))\n",
        "\n",
        "  test_ac=0\n",
        "  for b in range(0,len(test_ridx),batch_size) : \n",
        "    tr=test_ridx[b:b+batch_size]\n",
        "    input=torch.tensor(x[tr])\n",
        "    input=input.unsqueeze(1)\n",
        "    input=input.cuda()\n",
        "    output=torch.tensor(y[tr,0])\n",
        "    output=torch.tensor(output,dtype=torch.long)\n",
        "    output=output.cuda()\n",
        "    model_output=cnn(input)\n",
        "    for acc in range(0,model_output.shape[0]):\n",
        "      pre=torch.argmax(model_output[acc])\n",
        "      if pre==output[acc]: test_ac+=1;\n",
        "\n",
        "  print(\"test acc : \",test_ac/len(test_ridx))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  app.launch_new_instance()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "e :  0 loss :  tensor(4.5514, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  0 loss :  tensor(4.5630, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  0 loss :  tensor(4.6021, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  0 loss :  tensor(4.6099, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  0 loss :  tensor(4.5942, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  0 loss :  tensor(4.6020, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  0 loss :  tensor(4.5670, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.5975230309316089\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test acc :  0.5860385648035148\n",
            "e :  1 loss :  tensor(4.5514, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  1 loss :  tensor(4.5631, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  1 loss :  tensor(4.6021, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  1 loss :  tensor(4.6099, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  1 loss :  tensor(4.5942, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  1 loss :  tensor(4.6020, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  1 loss :  tensor(4.5670, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.5975230309316089\n",
            "test acc :  0.5860385648035148\n",
            "e :  2 loss :  tensor(4.5514, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  2 loss :  tensor(4.5629, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  2 loss :  tensor(4.6020, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  2 loss :  tensor(4.6098, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  2 loss :  tensor(4.5942, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  2 loss :  tensor(4.6019, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  2 loss :  tensor(4.5670, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.5975230309316089\n",
            "test acc :  0.5860385648035148\n",
            "e :  3 loss :  tensor(4.5514, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  3 loss :  tensor(4.5629, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  3 loss :  tensor(4.6020, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  3 loss :  tensor(4.6098, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  3 loss :  tensor(4.5941, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  3 loss :  tensor(4.6019, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  3 loss :  tensor(4.5669, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.5975230309316089\n",
            "test acc :  0.5860385648035148\n",
            "e :  4 loss :  tensor(4.5514, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  4 loss :  tensor(4.5629, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  4 loss :  tensor(4.6020, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  4 loss :  tensor(4.6098, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  4 loss :  tensor(4.5941, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  4 loss :  tensor(4.6019, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  4 loss :  tensor(4.5669, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "train acc :  0.5975230309316089\n",
            "test acc :  0.5860385648035148\n",
            "e :  5 loss :  tensor(4.5513, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  5 loss :  tensor(4.5629, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  5 loss :  tensor(4.6019, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  5 loss :  tensor(4.6098, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  5 loss :  tensor(4.5941, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "e :  5 loss :  tensor(4.6019, device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-6b41145c58b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0macc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m       \u001b[0mpre\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m       \u001b[0;32mif\u001b[0m \u001b[0mpre\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mac\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'e : '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"loss : \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}